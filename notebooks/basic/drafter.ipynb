{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence, TypedDict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage , ToolMessage, SystemMessage, BaseMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain.chat_models import init_chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    document_content: str\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "document_content = \"\"\n",
    "\n",
    "@tool\n",
    "def update(content: str) -> str:\n",
    "    \"\"\"Update the document content\"\"\"\n",
    "    global document_content\n",
    "    document_content = content\n",
    "    return f\"Document content updated to: {content}\"\n",
    "\n",
    "@tool\n",
    "def save(filename: str) -> str:\n",
    "    \"\"\"Save the document content\"\"\"\n",
    "    global document_content\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(document_content)\n",
    "    return f\"Document content saved to {filename}\"\n",
    "\n",
    "tools = [update, save]\n",
    "\n",
    "llm = init_chat_model(\"openai:gpt-4o-mini\").bind_tools(tools)\n",
    "\n",
    "def agent(state: State):\n",
    "    system_message = SystemMessage(content=f\"You are a helpful assistant that can update the document content and save it to a file. remember to save the document after each update. and show the document content after each update. {state['document_content']}\")\n",
    "    \n",
    "    if not state[\"messages\"]:\n",
    "        user_input = \"I'm ready to help you update a document. What would you like to create?\"\n",
    "        user_message = HumanMessage(content=user_input)\n",
    "    else:\n",
    "        user_input = input(\"\\nğŸ“ What would you like to do with the document? \")\n",
    "        print(f\"\\nğŸ‘¤ USER: {user_input}\")\n",
    "        user_message = HumanMessage(content=user_input)\n",
    "\n",
    "    all_messages = [system_message] + list(state[\"messages\"]) + [user_message]\n",
    "    \n",
    "    response = llm.invoke(all_messages)\n",
    "    \n",
    "    if hasattr(response, \"tool_calls\"):\n",
    "        print(response.tool_calls)\n",
    "    \n",
    "    return {\"messages\": list(all_messages) + [user_message, response]}\n",
    "\n",
    "def should_continue(state: State):\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    if not messages:\n",
    "        return 'continue'\n",
    "    \n",
    "    for message in reversed(messages):\n",
    "        if(isinstance(message, ToolMessage) and 'saved' in message.content.lower() and 'document' in message.content.lower()):\n",
    "            return 'end'\n",
    "        \n",
    "    return 'continue'\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
